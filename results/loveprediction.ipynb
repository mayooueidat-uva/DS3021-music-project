{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "edf30c9f",
      "metadata": {
        "id": "edf30c9f"
      },
      "source": [
        "Logistic Regression to predict if songs contain love"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "f64ac315",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "f64ac315"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "303c6fa0",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "303c6fa0"
      },
      "outputs": [],
      "source": [
        "#Read in datasets\n",
        "spotify_data = pd.read_csv(\"spotify_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "24a8183a",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "24a8183a"
      },
      "outputs": [],
      "source": [
        "#Adding Has Love column\n",
        "song_attribute_data = spotify_data\n",
        "\n",
        "titles = song_attribute_data[\"Song\"]\n",
        "titles = titles.str.split(pat=\" \", expand=True)\n",
        "\n",
        "song_attribute_data[\"Has Word Love?\"] = song_attribute_data['Song'].str.contains(\"Love\")\n",
        "song_attribute_data_love = song_attribute_data[song_attribute_data[\"Has Word Love?\"]]\n",
        "\n",
        "song_attribute_data = song_attribute_data.dropna()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "53896a96",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "53896a96"
      },
      "outputs": [],
      "source": [
        "#Prepare X and y\n",
        "y = song_attribute_data[\"Has Word Love?\"]\n",
        "X = song_attribute_data.loc[:,[\"speechiness\", \"valence\", \"tempo\", \"time_signature\", \"Popularity Points Awarded\"]]\n",
        "\n",
        "def minmax(z):\n",
        "    z = (z-min(z))/(max(z)-min(z))\n",
        "    return z\n",
        "X = X.apply(minmax,axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.2, random_state=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "01e8114f",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "01e8114f",
        "outputId": "8a694a67-904a-4b4b-b6e4-3af0d5bfca2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training R^2 0.9174862912350944\n",
            "Test R^2 0.9136790810998956\n"
          ]
        }
      ],
      "source": [
        "#Run Regression\n",
        "reg = LogisticRegression(penalty = None,\n",
        "                         fit_intercept=True,\n",
        "                         solver = 'newton-cholesky',\n",
        "                         max_iter=1000).fit(X_train,y_train)\n",
        "\n",
        "print(\"Training R^2\" , reg.score(X_train, y_train))\n",
        "print(\"Test R^2\", reg.score(X_test, y_test))\n",
        "#Pretty good accuracy scores for these predictors\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Run regression with all variables\n",
        "X_n = song_attribute_data.iloc[:, [8] + [9] + list(range(11, 24))]\n",
        "X_n = X_n.apply(minmax,axis=1)\n",
        "\n",
        "dummies = pd.DataFrame([])\n",
        "new_dummies = pd.get_dummies(song_attribute_data.loc[:,\"spotify_track_explicit\"], drop_first=True, dtype=int)\n",
        "dummies = pd.concat([dummies, new_dummies], axis=1, ignore_index=True)\n",
        "\n",
        "X2 = pd.concat([X_n,dummies],axis=1)\n",
        "X2.columns = X2.columns.astype(str)\n",
        "\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2,y, test_size=.2, random_state=100)\n",
        "\n",
        "reg2 = LogisticRegression(penalty = None,\n",
        "                         fit_intercept=True,\n",
        "                         solver = 'newton-cholesky',\n",
        "                         max_iter=1000).fit(X2_train,y2_train)\n",
        "\n",
        "print(\"Training R^2\", reg2.score(X2_train, y2_train))\n",
        "print(\"Test R^2\", reg2.score(X2_test, y2_test))\n",
        "#Exact same R^2 values?"
      ],
      "metadata": {
        "id": "C7-bNZSHcxvx",
        "outputId": "ecc361e1-4d41-4e8f-aa4f-c6b36d2625a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "C7-bNZSHcxvx",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training R^2 0.9174862912350944\n",
            "Test R^2 0.9136790810998956\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}